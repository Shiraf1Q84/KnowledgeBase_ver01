import os
import streamlit as st
import openai
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer, StorageContext, load_index_from_storage
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SimilarityPostprocessor
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é«˜åº¦ãªé¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# é‡è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
STORAGE_DIR = os.path.join(BASE_DIR, "storage")

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèªã¨ä½œæˆ
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(STORAGE_DIR, exist_ok=True)


# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main {
        font-family: Arial, sans-serif;
    }
    .stApp {
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
    }
    .search-container {
        display: flex;
        margin-bottom: 20px;
    }
    .search-input {
        flex-grow: 1;
        padding: 10px;
        font-size: 16px;
        border: 1px solid #dfe1e5;
        border-radius: 24px;
        outline: none;
    }
    .search-button {
        margin-left: 10px;
        padding: 10px 20px;
        font-size: 16px;
        background-color: #f8f9fa;
        border: 1px solid #f8f9fa;
        border-radius: 4px;
        color: #3c4043;
        cursor: pointer;
    }
    .search-button:hover {
        box-shadow: 0 1px 1px rgba(0,0,0,.1);
        background-color: #f8f9fa;
        border: 1px solid #dadce0;
        color: #202124;
    }
    .result-item {
        margin-bottom: 20px;
    }
    .result-title {
        color: #1a0dab;
        font-size: 18px;
        margin-bottom: 5px;
    }
    .result-url {
        color: #006621;
        font-size: 14px;
        margin-bottom: 5px;
    }
    .result-snippet {
        color: #545454;
        font-size: 14px;
    }
    .highlight {
        background-color: #ffffcc;
    }
</style>
""", unsafe_allow_html=True)



# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼å…¥åŠ›ã‚’é…ç½®
with st.sidebar:
    st.title("OpenAI API ã‚­ãƒ¼å…¥åŠ›")
    api_key = st.text_input("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=st.session_state.api_key, type="password")
    if st.button("APIã‚­ãƒ¼ã‚’è¨­å®š"):
        st.session_state.api_key = api_key
        openai.api_key = api_key
        st.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")

# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ã¾ãŸã¯èª­ã¿è¾¼ã¿
@st.cache_resource(show_spinner=False)
def get_vector_index():
    try:
        storage_context = StorageContext.from_defaults(persist_dir=STORAGE_DIR)
        if os.path.exists(os.path.join(STORAGE_DIR, "docstore.json")):
            # æ—¢å­˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã‚€
            index = load_index_from_storage(storage_context)
            st.sidebar.success("æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        else:
            # æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹
            with st.spinner(text="ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
                if not os.listdir(DATA_DIR):
                    st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {DATA_DIR} ãŒç©ºã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
                    return None
                reader = SimpleDirectoryReader(input_dir=DATA_DIR, recursive=True)
                docs = reader.load_data()
                embed_model = OpenAIEmbedding(openai_api_key=openai.api_key)
                index = VectorStoreIndex.from_documents(docs, storage_context=storage_context)
                index.storage_context.persist()
            st.sidebar.success("æ–°ã—ã„ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
        return index
    except Exception as e:
        st.error(f"ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# ãã®ä»–ã®é–¢æ•°ï¼ˆsplit_into_chunks, score_chunks, select_best_chunks, highlight_textï¼‰ã¯å¤‰æ›´ãªã—...

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹é–¢æ•°
def split_into_chunks(text, chunk_size=200, overlap=50):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

# ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°
def score_chunks(chunks, query):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(chunks + [query])
    query_vector = tfidf_matrix[-1]
    chunk_vectors = tfidf_matrix[:-1]
    similarities = cosine_similarity(chunk_vectors, query_vector)
    return similarities.flatten()

# æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠã™ã‚‹é–¢æ•°
def select_best_chunks(chunks, scores, num_chunks=2):
    sorted_chunks = [chunk for _, chunk in sorted(zip(scores, chunks), reverse=True)]
    return sorted_chunks[:num_chunks]

# ãƒã‚¤ãƒ©ã‚¤ãƒˆé–¢æ•°
def highlight_text(text, query):
    words = query.lower().split()
    for word in words:
        text = re.sub(f'(?i){re.escape(word)}', lambda m: f'<span class="highlight">{m.group()}</span>', text)
    return text




# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if st.session_state.api_key:
    index = get_vector_index()
    
    if index is not None:
        st.title("é«˜åº¦ãªé¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢")
        
        # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form(key='search_form'):
            query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="search_input")
            submit_button = st.form_submit_button(label='æ¤œç´¢')
        
        if submit_button and query:
            with st.spinner("æ¤œç´¢ä¸­..."):
                # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
                retriever = VectorIndexRetriever(
                    index=index,
                    similarity_top_k=10,
                )
                response_synthesizer = get_response_synthesizer()
                query_engine = RetrieverQueryEngine(
                    retriever=retriever,
                    response_synthesizer=response_synthesizer,
                    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],
                )
                
                # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
                response = query_engine.query(query)
                
                # æ¤œç´¢çµæœã®è¡¨ç¤ºï¼ˆå¤‰æ›´ãªã—ï¼‰...
                

            # æ¤œç´¢çµæœã®è¡¨ç¤º
            for i, node in enumerate(response.source_nodes, 1):
                content = node.node.get_content()
                score = node.score if hasattr(node, 'score') else 'N/A'
                file_name = node.node.metadata.get('file_name', 'ä¸æ˜')
                
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
                chunks = split_into_chunks(content)
                
                # ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
                chunk_scores = score_chunks(chunks, query)
                
                # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠ
                best_chunks = select_best_chunks(chunks, chunk_scores)
                
                # é¸æŠã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                highlighted_content = "...".join([highlight_text(chunk, query) for chunk in best_chunks])
                
                # çµæœè¡¨ç¤º
                st.markdown(f"""
                <div class="result-item">
                    <div class="result-title">{file_name}</div>
                    <div class="result-url">é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.2f}</div>
                    <div class="result-snippet">{highlighted_content}</div>
                </div>
                """, unsafe_allow_html=True)
                
                # å…ƒã®è³‡æ–™ã¸ã®ãƒªãƒ³ã‚¯
                file_path = os.path.join("data", file_name)
                if os.path.exists(file_path):
                    with open(file_path, "r") as f:
                        file_content = f.read()
                    st.download_button(
                        label=f"å…ƒã®è³‡æ–™ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=file_content,
                        file_name=file_name,
                        mime="text/plain",
                        key=f"download_button_{i}"
                    )
                    
                # ç·åˆå›ç­”ã®è¡¨ç¤º
                st.subheader("ç·åˆå›ç­”:")
                st.write(response)
    else:
        st.warning("ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‹ã„ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ãƒœã‚¿ãƒ³
if st.sidebar.button("ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°"):
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
    st.cache_resource.clear()
    # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
    import shutil
    if os.path.exists(STORAGE_DIR):
        shutil.rmtree(STORAGE_DIR)
    st.sidebar.success("ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
    st.experimental_rerun()