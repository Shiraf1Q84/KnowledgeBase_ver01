import os
import streamlit as st
import openai
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SimilarityPostprocessor
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Streamlitãƒšãƒ¼ã‚¸è¨­å®šï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æœ€åˆã®Streamlitã‚³ãƒãƒ³ãƒ‰ã¨ã—ã¦é…ç½®ï¼‰
st.set_page_config(
    page_title="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢",
    page_icon="ğŸŒ¸",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    body {
        color: #a388ee;
        background-color: #ffffff;
    }
    .main {
        font-family: 'Comic Sans MS', cursive, sans-serif;
    }
    .stApp {
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        background-color: #ffffff;
    }
    .search-container {
        display: flex;
        margin-bottom: 20px;
    }
    .search-input {
        flex-grow: 1;
        padding: 10px;
        font-size: 16px;
        border: 2px solid #ffd1dc;
        border-radius: 24px;
        outline: none;
        background-color: #fffafa;
    }
    .search-button {
        margin-left: 10px;
        padding: 10px 20px;
        font-size: 16px;
        background-color: #ffd1dc;
        border: none;
        border-radius: 24px;
        color: #ffffff;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .search-button:hover {
        background-color: #ffb6c1;
        transform: scale(1.05);
    }
    .result-item {
        margin-bottom: 20px;
        padding: 15px;
        border-radius: 15px;
        background-color: #f0f8ff;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .result-title {
        color: #ff69b4;
        font-size: 20px;
        margin-bottom: 5px;
    }
    .result-url {
        color: #20b2aa;
        font-size: 14px;
        margin-bottom: 5px;
    }
    .result-snippet {
        color: #778899;
        font-size: 16px;
    }
    .highlight {
        background-color: #fffacd;
        padding: 2px 4px;
        border-radius: 4px;
    }
    .stButton>button {
        background-color: #ffd1dc;
        color: white;
        border: none;
        border-radius: 24px;
        padding: 10px 20px;
        font-size: 16px;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #ffb6c1;
        transform: scale(1.05);
    }
    .css-1dp5vir {
        background-color: #ffffff;
    }
    .css-18e3th9 {
        padding-top: 1rem;
        padding-bottom: 10rem;
        padding-left: 5rem;
        padding-right: 5rem;
    }
    .css-1d391kg {
        padding-top: 3.5rem;
        padding-right: 1rem;
        padding-bottom: 3.5rem;
        padding-left: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«APIã‚­ãƒ¼å…¥åŠ›ã‚’é…ç½®
with st.sidebar:
    st.title("ğŸŒˆ OpenAI API ã‚­ãƒ¼å…¥åŠ›")
    api_key = st.text_input("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=st.session_state.api_key, type="password")
    if st.button("APIã‚­ãƒ¼ã‚’è¨­å®š"):
        st.session_state.api_key = api_key
        openai.api_key = api_key
        st.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ âœ¨")

# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰
@st.cache_resource(show_spinner=False)
def build_vector_database():
    with st.spinner(text="âœ¨ ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­... âœ¨"):
        reader = SimpleDirectoryReader(
            input_dir="./data",
            recursive=True,
            encoding="utf-8",  # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
            errors="ignore"    # ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–
        )
        docs = reader.load_data()
        embed_model = OpenAIEmbedding(openai_api_key=openai.api_key)
        index = VectorStoreIndex.from_documents(docs)
        return index

# ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹é–¢æ•°
def split_into_chunks(text, chunk_size=200, overlap=50):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = " ".join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

# ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°
def score_chunks(chunks, query):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(chunks + [query])
    query_vector = tfidf_matrix[-1]
    chunk_vectors = tfidf_matrix[:-1]
    similarities = cosine_similarity(chunk_vectors, query_vector)
    return similarities.flatten()

# æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠã™ã‚‹é–¢æ•°
def select_best_chunks(chunks, scores, num_chunks=2):
    sorted_chunks = [chunk for _, chunk in sorted(zip(scores, chunks), reverse=True)]
    return sorted_chunks[:num_chunks]

# ãƒã‚¤ãƒ©ã‚¤ãƒˆé–¢æ•°
def highlight_text(text, query):
    words = query.lower().split()
    for word in words:
        text = re.sub(f'(?i){re.escape(word)}', lambda m: f'<span class="highlight">{m.group()}</span>', text)
    return text

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if st.session_state.api_key:
    try:
        index = build_vector_database()
        
        st.title("ğŸŒ¸ ã‹ã‚ã„ã„é¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ ğŸŒ¸")
        
        # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form(key='search_form'):
            query = st.text_input("ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="search_input")
            submit_button = st.form_submit_button(label='æ¤œç´¢ ğŸš€')
        
        if submit_button and query:
            with st.spinner("ğŸ” ã‹ã‚ã„ãæ¤œç´¢ä¸­..."):
                # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
                retriever = VectorIndexRetriever(
                    index=index,
                    similarity_top_k=10,
                )
                response_synthesizer = get_response_synthesizer()
                query_engine = RetrieverQueryEngine(
                    retriever=retriever,
                    response_synthesizer=response_synthesizer,
                    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],
                )
                
                # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
                response = query_engine.query(query)
                
                # æ¤œç´¢çµæœã®è¡¨ç¤º
                for i, node in enumerate(response.source_nodes, 1):
                    content = node.node.get_content()
                    score = node.score if hasattr(node, 'score') else 'N/A'
                    file_name = node.node.metadata.get('file_name', 'ä¸æ˜')
                    
                    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
                    chunks = split_into_chunks(content)
                    
                    # ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
                    chunk_scores = score_chunks(chunks, query)
                    
                    # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠ
                    best_chunks = select_best_chunks(chunks, chunk_scores)
                    
                    # é¸æŠã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
                    highlighted_content = "...".join([highlight_text(chunk, query) for chunk in best_chunks])
                    
                    # çµæœè¡¨ç¤º
                    st.markdown(f"""
                    <div class="result-item">
                        <div class="result-title">ğŸ“„ {file_name}</div>
                        <div class="result-url">ğŸ’– é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.2f}</div>
                        <div class="result-snippet">{highlighted_content}</div>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # å…ƒã®è³‡æ–™ã¸ã®ãƒªãƒ³ã‚¯
                    file_path = os.path.join("data", file_name)
                    if os.path.exists(file_path):
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            file_content = f.read()
                        st.download_button(
                            label=f"ğŸ“¥ å…ƒã®è³‡æ–™ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=file_content,
                            file_name=file_name,
                            mime="text/plain",
                            key=f"download_button_{i}"
                        )
                
                # ç·åˆå›ç­”ã®è¡¨ç¤º
                st.subheader("âœ¨ ç·åˆå›ç­”:")
                st.write(response)
    except Exception as e:
        st.error(f"ğŸ˜¢ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒUTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    st.warning("ğŸ”‘ OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‹ã„ã¦è¨­å®šã—ã¦ãã ã•ã„ã€‚")
