import os
import streamlit as st
import openai
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SimilarityPostprocessor
import re

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="é«˜åº¦ãªé¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="auto",
)

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

st.sidebar.title("OpenAI API ã‚­ãƒ¼å…¥åŠ›")
api_key = st.sidebar.text_input("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", value=st.session_state.api_key, type="password")
if st.sidebar.button("APIã‚­ãƒ¼ã‚’è¨­å®š"):
    st.session_state.api_key = api_key
    openai.api_key = api_key
    st.sidebar.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")

# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰
@st.cache_resource(show_spinner=False)
def build_vector_database():
    with st.spinner(text="ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ä¸­..."):
        reader = SimpleDirectoryReader(input_dir="./data", recursive=True)
        docs = reader.load_data()
        embed_model = OpenAIEmbedding(openai_api_key=openai.api_key)
        index = VectorStoreIndex.from_documents(docs)
        return index

# ãƒã‚¤ãƒ©ã‚¤ãƒˆé–¢æ•°
def highlight_text(text, query):
    words = query.lower().split()
    for word in words:
        text = re.sub(f'(?i){re.escape(word)}', lambda m: f'<span style="background-color: yellow;">{m.group()}</span>', text)
    return text

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if st.session_state.api_key:
    index = build_vector_database()
    
    st.title("é«˜åº¦ãªé¡ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢")
    query = st.text_input("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
    
    if query:
        with st.spinner("æ¤œç´¢ä¸­..."):
            # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®š
            retriever = VectorIndexRetriever(
                index=index,
                similarity_top_k=10,
            )
            response_synthesizer = get_response_synthesizer()
            query_engine = RetrieverQueryEngine(
                retriever=retriever,
                response_synthesizer=response_synthesizer,
                node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],
            )
            
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            response = query_engine.query(query)
            
            st.subheader("æ¤œç´¢çµæœ:")
            
            # ã‚½ãƒ¼ã‚¹ãƒãƒ¼ãƒ‰ã®å‡¦ç†
            for i, node in enumerate(response.source_nodes, 1):
                content = node.node.get_content()
                score = node.score if hasattr(node, 'score') else 'N/A'
                
                # é‡è¦ç®‡æ‰€ã®æŠ½å‡ºï¼ˆã“ã®ä¾‹ã§ã¯ã€ã‚¯ã‚¨ãƒªã«æœ€ã‚‚é–¢é€£ã™ã‚‹1-2æ–‡ã‚’æŠ½å‡ºï¼‰
                sentences = content.split('ã€‚')
                relevant_sentences = [sent for sent in sentences if any(word in sent.lower() for word in query.lower().split())][:2]
                highlighted_content = highlight_text('ã€‚'.join(relevant_sentences), query)
                
                # çµæœè¡¨ç¤º
                with st.expander(f"çµæœ {i} (é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.2f})"):
                    st.markdown(highlighted_content, unsafe_allow_html=True)
                    if st.button(f"å…¨æ–‡ã‚’è¡¨ç¤º #{i}"):
                        st.text_area("å…¨æ–‡", content, height=300)
                
            # ç·åˆå›ç­”ã®è¡¨ç¤º
            st.subheader("ç·åˆå›ç­”:")
            st.write(response)
else:
    st.warning("OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")